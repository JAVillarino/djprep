# djprep - Claude Code Implementation Guide

**Repository:** https://github.com/JAVillarino/djprep

## Project Overview

djprep is a CLI tool that analyzes audio files (MP3, WAV, FLAC, AIFF) to extract BPM, musical key, and optionally separate stems. It outputs Rekordbox-compatible XML for import into Pioneer DJ software, plus a JSON sidecar for interoperability.

**Core value proposition:** Free, open-source alternative to Mixed In Key with stem separation capabilities.

---

## Current Project State (January 2026)

The project is **feature-complete** and ready for v0.1.0 release:

| Component | Status | Notes |
|-----------|--------|-------|
| CLI (clap) | ‚úÖ Complete | `--input`, `--output`, `--verbose`, `--stems`, `--dry-run`, `--force` |
| File Discovery | ‚úÖ Complete | walkdir, filters by extension |
| Audio Decoding | ‚úÖ Complete | symphonia, 22050Hz mono for analysis, 44100Hz stereo for stems |
| BPM Detection | ‚úÖ Complete | stratum-dsp 1.0, genre-aware tempo correction |
| Key Detection | ‚úÖ Complete | stratum-dsp 1.0, Camelot/Open Key notation |
| Stem Separation | ‚úÖ Complete | ort 2.0 + HTDemucs, auto-download, GPU acceleration |
| Metadata Extraction | ‚úÖ Complete | lofty 0.18, ID3v2/Vorbis/AIFF tags |
| Rekordbox XML | ‚úÖ Complete | Streaming writer, URI encoding |
| JSON Export | ‚úÖ Complete | Sidecar file with full analysis data |
| Progress Bars | ‚úÖ Complete | indicatif multi-progress |
| Error Handling | ‚úÖ Complete | Actionable error messages with suggestions |
| Concurrency | ‚úÖ Complete | Bounded channel queue for stem backpressure |
| Incremental Analysis | ‚úÖ Complete | Skips already-analyzed files (--force to override) |
| Tests | ‚úÖ Complete | 38 unit + 13 integration + 2 doc tests |

**All Phase 5 (Polish) items complete:**
- ‚úÖ Metadata extraction (ID3/Vorbis tags)
- ‚úÖ Integration tests with sample audio
- ‚úÖ Improved error messages with actionable guidance
- ‚úÖ Model auto-discovery (checks multiple locations)
- ‚úÖ Automatic model download from Hugging Face (~200MB, with progress bar)
- ‚úÖ Dry-run mode
- ‚úÖ Incremental analysis (--force flag)

---

## How to Use Claude Code on This Project

### Starting a Session
```bash
cd /path/to/djprep
claude
```

### Effective Prompts for Claude Code

**To add a new export format (e.g., Serato):**
```
Add Serato export format support.

Requirements:
- Research Serato crate file format
- Create src/export/serato.rs module
- Add --format serato CLI option
- Test with real Serato installation if possible
```

**To optimize performance:**
```
Profile and optimize the analysis pipeline for large libraries.

Steps:
1. Add benchmarks using criterion
2. Profile memory usage with valgrind/heaptrack
3. Identify bottlenecks
4. Implement optimizations
```

**To debug/understand code:**
```
Explain how the pipeline orchestrator works and trace the data flow from
file discovery through to XML export.
```

**To run tests:**
```
Run cargo test and fix any failures. Then run cargo clippy and address warnings.
```

---

## Technical Constraints

### Core Dependencies
- **Rust 1.75+** - Memory safety, single binary distribution
- **symphonia** - Pure Rust audio decoding (no FFmpeg dependency)
- **stratum-dsp 1.0** - BPM and key detection (pure Rust, zero C dependencies)
- **lofty 0.18** - Metadata extraction from ID3v2, Vorbis, AIFF tags
- **ort 2.0** - ONNX Runtime for HTDemucs stem separation (feature-gated)
- **rustfft 6.2** - STFT preprocessing for stem separation
- **rayon** - Data parallelism for batch processing
- **crossbeam-channel** - Bounded channel for stem backpressure
- **quick-xml** - Streaming XML writer for large libraries
- **clap** - CLI argument parsing

### Architecture Principles
1. **Trait abstractions** for analysis backends (swap implementations later)
2. **Staged pipeline** with backpressure between CPU analysis and GPU inference
3. **Streaming output** - don't hold entire XML in memory
4. **Graceful degradation** - if stems fail, still output BPM/key

---

## Data Types

```rust
// Core analysis results
pub struct AnalysisResult {
    pub track_id: i32,          // Deterministic, derived from path hash
    pub bpm: f64,
    pub bpm_confidence: f64,
    pub key: KeyResult,
    pub duration_seconds: f64,
    pub stems: Option<StemPaths>,
}

pub struct KeyResult {
    pub pitch_class: PitchClass,  // C, Cs, D, Ds, E, F, Fs, G, Gs, A, As, B
    pub mode: Mode,               // Major, Minor
    pub camelot: String,          // "1A" through "12B"
}

pub enum PitchClass { C, Cs, D, Ds, E, F, Fs, G, Gs, A, As, B }
pub enum Mode { Major, Minor }

pub struct StemPaths {
    pub vocals: PathBuf,
    pub drums: PathBuf,
    pub bass: PathBuf,
    pub other: PathBuf,
}
```

---

## Module Structure

Current directory structure:

```
src/
‚îú‚îÄ‚îÄ main.rs                 # Entry point, CLI setup
‚îú‚îÄ‚îÄ lib.rs                  # Public API, re-exports
‚îú‚îÄ‚îÄ error.rs                # Error types (thiserror)
‚îú‚îÄ‚îÄ types.rs                # Core data types (AnalyzedTrack, BpmResult, KeyResult, etc.)
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îî‚îÄ‚îÄ settings.rs         # Settings struct, CLI parsing
‚îÇ
‚îú‚îÄ‚îÄ discovery/
‚îÇ   ‚îî‚îÄ‚îÄ mod.rs              # walkdir file discovery, track ID generation
‚îÇ
‚îú‚îÄ‚îÄ audio/
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îî‚îÄ‚îÄ decoder.rs          # symphonia decoding (22050Hz mono + 44100Hz stereo)
‚îÇ
‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îú‚îÄ‚îÄ traits.rs           # BpmDetector, KeyDetector, StemSeparator traits
‚îÇ   ‚îú‚îÄ‚îÄ stratum.rs          # stratum-dsp BPM/Key implementation
‚îÇ   ‚îú‚îÄ‚îÄ camelot.rs          # Key to Camelot notation mapping
‚îÇ   ‚îú‚îÄ‚îÄ metadata.rs         # ID3/Vorbis tag extraction via lofty
‚îÇ   ‚îî‚îÄ‚îÄ stems/
‚îÇ       ‚îú‚îÄ‚îÄ mod.rs
‚îÇ       ‚îú‚îÄ‚îÄ model.rs        # ONNX model download/cache
‚îÇ       ‚îú‚îÄ‚îÄ separator.rs    # OrtStemSeparator - ort session management
‚îÇ       ‚îú‚îÄ‚îÄ stft.rs         # STFT/ISTFT preprocessing (rustfft)
‚îÇ       ‚îî‚îÄ‚îÄ chunking.rs     # Audio chunking with overlap-add
‚îÇ
‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.rs     # Batch processing with bounded channel queue
‚îÇ
‚îî‚îÄ‚îÄ export/
    ‚îú‚îÄ‚îÄ mod.rs
    ‚îú‚îÄ‚îÄ rekordbox.rs        # XML generation (streaming)
    ‚îî‚îÄ‚îÄ json.rs             # JSON sidecar export
```

---

## Implementation Phases

### Phase 1: Walking Skeleton ‚úÖ COMPLETE
**Goal:** End-to-end data flow with hardcoded values

- CLI with clap, file discovery with walkdir
- symphonia decoding, basic XML output

### Phase 2: Real Analysis ‚úÖ COMPLETE
**Goal:** Accurate BPM and key detection

- stratum-dsp 1.0 integration (replaced bliss-audio due to FFI issues)
- Camelot mapping, TrackID generation (FNV-1a)
- Genre-aware tempo correction

### Phase 3: Batch Processing ‚úÖ COMPLETE
**Goal:** Efficient parallel processing

- rayon parallel iteration
- indicatif progress bars
- JSON sidecar export

### Phase 4: Stem Separation ‚úÖ COMPLETE
**Goal:** HTDemucs integration

- ort 2.0 session with EP fallback (CoreML ‚Üí DirectML ‚Üí CPU)
- STFT preprocessing with rustfft (nfft=4096, hop_length=1024)
- 7.8-second chunking with 1-second overlap
- Overlap-add reconstruction with linear crossfade
- Bounded channel queue (capacity=4) with dedicated stem worker thread
- WAV output via hound crate

### Phase 5: Polish ‚úÖ COMPLETE
**Goal:** Production ready

1. ‚úÖ The "djprep_import_" playlist workaround for Rekordbox bug
2. ‚úÖ Metadata extraction (ID3/Vorbis tags via lofty)
3. ‚úÖ Integration tests with sample audio (9 tests)
4. ‚úÖ Improved error messages with actionable suggestions
5. ‚úÖ Model auto-discovery (checks 5 common locations)
6. ‚úÖ Dry-run mode (--dry-run flag)
7. ‚úÖ Incremental analysis (--force flag to re-analyze)

---

## Critical Implementation Details

### TrackID Generation

Rekordbox uses signed 32-bit integers. Generate deterministically:

```rust
use std::hash::{Hash, Hasher};
use hash32::{FnvHasher, Hasher as Hash32Hasher};

fn generate_track_id(path: &Path) -> i32 {
    let normalized = normalize_path(path);
    let mut hasher = FnvHasher::default();
    hasher.write(normalized.as_bytes());
    let hash = hasher.finish32();
    (hash & 0x7FFFFFFF) as i32  // Ensure positive
}

fn normalize_path(path: &Path) -> String {
    let s = path.to_string_lossy();
    let s = s.replace('\\', "/");
    let s = s.to_lowercase();
    // Strip trailing slashes
    s.trim_end_matches('/').to_string()
}
```

### URI Encoding for Rekordbox

```rust
use percent_encoding::{utf8_percent_encode, AsciiSet, CONTROLS};

const ENCODE_SET: &AsciiSet = &CONTROLS
    .add(b' ')
    .add(b'"')
    .add(b'#')
    .add(b'<')
    .add(b'>')
    .add(b'`')
    .add(b'?')
    .add(b'{')
    .add(b'}')
    .add(b'[')
    .add(b']');

fn path_to_rekordbox_uri(path: &Path) -> String {
    let path_str = path.to_string_lossy();
    let normalized = path_str.replace('\\', "/");
    
    // Add leading slash for Windows drive letters
    let normalized = if normalized.chars().nth(1) == Some(':') {
        format!("/{}", normalized)
    } else {
        normalized.to_string()
    };
    
    // Encode each path segment separately (preserve slashes)
    let encoded: String = normalized
        .split('/')
        .map(|seg| utf8_percent_encode(seg, ENCODE_SET).to_string())
        .collect::<Vec<_>>()
        .join("/");
    
    format!("file://localhost{}", encoded)
}
```

### Camelot Wheel Mapping

```rust
fn to_camelot(pitch_class: PitchClass, mode: Mode) -> String {
    use PitchClass::*;
    use Mode::*;
    
    match (pitch_class, mode) {
        (C, Major) => "8B",   (C, Minor) => "5A",
        (Cs, Major) => "3B",  (Cs, Minor) => "12A",
        (D, Major) => "10B",  (D, Minor) => "7A",
        (Ds, Major) => "5B",  (Ds, Minor) => "2A",
        (E, Major) => "12B",  (E, Minor) => "9A",
        (F, Major) => "7B",   (F, Minor) => "4A",
        (Fs, Major) => "2B",  (Fs, Minor) => "11A",
        (G, Major) => "9B",   (G, Minor) => "6A",
        (Gs, Major) => "4B",  (Gs, Minor) => "1A",
        (A, Major) => "11B",  (A, Minor) => "8A",
        (As, Major) => "6B",  (As, Minor) => "3A",
        (B, Major) => "1B",   (B, Minor) => "10A",
    }.to_string()
}
```

### Rekordbox XML Structure

```xml
<?xml version="1.0" encoding="UTF-8"?>
<DJ_PLAYLISTS Version="1.0.0">
  <PRODUCT Name="djprep" Version="0.1.0" Company=""/>
  <COLLECTION Entries="2">
    <TRACK TrackID="123456" Name="Track Name" Artist="Artist" 
           Album="" Kind="MP3 File" Size="10485760"
           TotalTime="300" AverageBpm="128.00" 
           Tonality="11B" Location="file://localhost/path/to/track.mp3"
           DateAdded="2024-01-15"/>
  </COLLECTION>
  <PLAYLISTS>
    <NODE Type="0" Name="ROOT" Count="1">
      <NODE Type="1" Name="djprep_import_20240115" KeyType="0" Entries="2">
        <TRACK Key="123456"/>
        <TRACK Key="789012"/>
      </NODE>
    </NODE>
  </PLAYLISTS>
</DJ_PLAYLISTS>
```

**IMPORTANT:** Always generate the `djprep_import_*` playlist. This is a workaround for a Rekordbox bug where direct XML import doesn't update existing tracks. Users must import via the playlist.

### Concurrency Model

```
Discovery (single thread)
    ‚îÇ
    ‚ñº
Analysis Pool (N-2 threads, rayon)
    ‚îÇ
    ‚îú‚îÄ‚îÄ‚ñ∫ [BPM/Key only tracks] ‚îÄ‚îÄ‚ñ∫ Results Channel ‚îÄ‚îÄ‚ñ∫ Export Thread
    ‚îÇ
    ‚îî‚îÄ‚îÄ‚ñ∫ [Stems requested] ‚îÄ‚îÄ‚ñ∫ Bounded Channel (cap=2) ‚îÄ‚îÄ‚ñ∫ Stem Worker (1 thread)
                                                              ‚îÇ
                                                              ‚ñº
                                                         Results Channel ‚îÄ‚îÄ‚ñ∫ Export Thread
```

The bounded channel between Analysis and Stems provides backpressure. When GPU is busy, analysis naturally slows.

### ort Execution Provider Selection

Try in order: CUDA ‚Üí CoreML ‚Üí DirectML ‚Üí CPU

```rust
fn create_stem_session(model_path: &Path) -> Result<ort::Session> {
    let builder = ort::Session::builder()?;
    
    // Try CUDA first (NVIDIA)
    #[cfg(feature = "cuda")]
    if let Ok(session) = builder.clone()
        .with_execution_providers([ort::CUDAExecutionProvider::default().build()])?
        .commit_from_file(model_path) {
        info!("Using CUDA for stem separation");
        return Ok(session);
    }
    
    // Try CoreML (Apple Silicon)
    #[cfg(target_os = "macos")]
    if let Ok(session) = builder.clone()
        .with_execution_providers([ort::CoreMLExecutionProvider::default().build()])?
        .commit_from_file(model_path) {
        info!("Using CoreML for stem separation");
        return Ok(session);
    }
    
    // Fallback to CPU
    info!("Using CPU for stem separation (this will be slow)");
    builder.commit_from_file(model_path)
}
```

---

## Cargo.toml

```toml
[package]
name = "djprep"
version = "0.1.0"
edition = "2021"
rust-version = "1.75"
description = "High-performance audio analysis for DJs - BPM, Key, and Stem separation"
license = "MIT"

[features]
default = []
stems = ["dep:ort", "dep:reqwest", "dep:sha2", "dep:hex", "dep:rustfft", "dep:ndarray"]

[dependencies]
# CLI & UX
clap = { version = "4", features = ["derive"] }
indicatif = { version = "0.17", features = ["rayon"] }

# Audio decoding
symphonia = { version = "0.5", features = ["mp3", "flac", "wav", "aiff", "pcm"] }

# Analysis - stratum-dsp for BPM/key detection (pure Rust, no FFI)
stratum-dsp = "1.0"

# Metadata extraction
lofty = "0.18"

# Stem separation (optional, feature-gated)
ort = { version = "2.0.0-rc.10", optional = true }
rustfft = { version = "6.2", optional = true }
ndarray = { version = "0.16", optional = true }

# Concurrency
rayon = "1.10"
crossbeam-channel = "0.5"
num_cpus = "1.16"

# Serialization
quick-xml = { version = "0.37", features = ["serialize"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Utilities
thiserror = "2"
anyhow = "1"
walkdir = "2"
percent-encoding = "2"
chrono = { version = "0.4", features = ["serde"] }
directories = "5"
hash32 = "0.3"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Audio writing (for stems)
hound = "3.5"

# Model download (optional, for stems)
reqwest = { version = "0.12", features = ["blocking", "rustls-tls"], default-features = false, optional = true }
sha2 = { version = "0.10", optional = true }
hex = { version = "0.4", optional = true }

[dev-dependencies]
tempfile = "3"

[profile.release]
lto = true
strip = true
panic = "abort"
codegen-units = 1
```

---

## CLI Interface

```
djprep - High-performance audio analysis for DJs

USAGE:
    djprep [OPTIONS] --input <PATH> --output <DIR>

OPTIONS:
    -i, --input <PATH>      Input path (file or directory)
    -o, --output <DIR>      Output directory for XML/JSON files

    --stems                 Enable stem separation (GPU recommended)
    --stems-output <DIR>    Directory for stem files [default: <output>/stems]
    --genre <GENRE>         Genre hint for BPM detection (resolves double-tempo)
                            [values: house, techno, trance, dnb, dubstep,
                             hiphop, pop, rock]

    -j, --threads <N>       Number of worker threads [default: CPU count - 2]
    -r, --recursive         Scan subdirectories [default: true]
    --force                 Re-analyze all files (by default, skips already-analyzed)
    --json                  Output JSON in addition to XML [default: true]
    --dry-run               Show files that would be analyzed without processing

    -v, --verbose           Increase verbosity (-v, -vv, -vvv)
    -q, --quiet             Suppress progress bars
    -h, --help              Print help
    -V, --version           Print version

EXAMPLES:
    djprep -i ./music -o ./analyzed
    djprep -i ./music --stems --genre dnb -o ./analyzed
    djprep -i ./music -o ./out --dry-run
    djprep -i ./music -o ./out --force
```

---

## Error Handling Strategy

Use `thiserror` for library errors, `anyhow` in main for ergonomics:

```rust
// src/error.rs
#[derive(Debug, thiserror::Error)]
pub enum DjprepError {
    #[error("Failed to decode audio: {path}")]
    DecodeError {
        path: PathBuf,
        #[source]
        source: symphonia::core::errors::Error,
    },
    
    #[error("Analysis failed for {path}: {reason}")]
    AnalysisError {
        path: PathBuf,
        reason: String,
    },
    
    #[error("Stem separation failed: {0}")]
    StemError(String),
    
    #[error("Failed to write output: {0}")]
    OutputError(#[from] std::io::Error),
    
    #[error("Model not found and download failed: {0}")]
    ModelError(String),
}

// Per-file errors are collected, not fatal
pub struct BatchResult {
    pub succeeded: Vec<AnalysisResult>,
    pub failed: Vec<(PathBuf, DjprepError)>,
}
```

---

## Testing Approach

### Unit tests (no audio files needed)
- URI encoding edge cases
- Camelot mapping correctness
- TrackID generation determinism
- XML escaping

### Integration tests (need small fixtures)
- Create 1-second test WAV files programmatically
- Verify pipeline produces valid XML

### Manual testing
- Use real tracks with known BPM/key
- Compare against Rekordbox/Mixed In Key output

---

## Next Steps (Post v0.1.0)

All core functionality is complete. Future enhancements:

### Priority 1: Additional Export Formats

```
Add support for Serato and Traktor export formats.

Research needed:
- Serato DJ crate format (.crate files)
- Traktor NML format
- What metadata each software expects

Implementation:
- New export modules: src/export/serato.rs, src/export/traktor.rs
- CLI flag: --format rekordbox|serato|traktor|all
```

### Priority 2: Waveform Generation

```
Generate waveform data for visual display.

Options:
- Peak amplitude per segment
- RMS levels
- Frequency bands (low/mid/high)
- Output as JSON or binary format
```

### Priority 3: Performance Optimization

```
Benchmark and optimize for large libraries (10,000+ tracks).

Areas to investigate:
- Memory usage during batch processing
- Parallel I/O for file reading
- Caching intermediate results
```

---

## Notes for Claude Code

### Do's
1. **Read CLAUDE.md first** - This file contains all architectural decisions
2. **Test incrementally** - `cargo run` and `cargo check` after each change
3. **Use existing patterns** - Look at StratumBpmDetector in src/analysis/stratum.rs
4. **Check compilation** - Run `cargo check` before claiming code is complete
5. **Handle errors** - Use `?` operator, don't unwrap() in library code
6. **Feature-gate stem code** - Use `#[cfg(feature = "stems")]` for ort/rustfft code

### Don'ts
1. **Don't refactor working code** unless asked - Focus on the task at hand
2. **Don't add dependencies** without checking if they're needed
3. **Don't ignore the trait abstractions** - They exist for swappability
4. **Don't block rayon threads** with stem separation - Use the bounded channel queue

### Debugging Commands
```bash
# Check compilation (default features)
cargo check

# Check with stems feature
cargo check --features stems

# Run with verbose logging
RUST_LOG=debug cargo run -- -i ./test -o ./out

# Run with stems enabled (model auto-downloads on first run)
cargo run --features stems -- -i ./test -o ./out --stems

# Run all tests
cargo test

# Run tests with stems feature
cargo test --features stems

# Check for issues
cargo clippy
cargo clippy --features stems

# Format code
cargo fmt
```

### Key Files to Understand
```
src/analysis/traits.rs       # Trait definitions (BpmDetector, KeyDetector, StemSeparator)
src/analysis/stratum.rs      # BPM/Key detection implementation
src/analysis/stems/model.rs  # Model auto-download and caching
src/analysis/stems/separator.rs  # Stem separation with ort
src/pipeline/orchestrator.rs # Main pipeline with bounded channel queue
src/types.rs                 # Data structures (AnalyzedTrack, BpmResult, KeyResult)
src/error.rs                 # Error types (DjprepError enum)
```

When stuck on Rust specifics (ownership, lifetimes, traits), ask for help. When stuck on architecture decisions, refer back to this document.

---

## AI Code Quality Checklist

**MANDATORY**: After ANY significant code generation, run this checklist before considering the task complete.

### Pre-Commit Verification
```bash
# 1. Compile check
cargo check

# 2. Run all tests
cargo test

# 3. Clippy with strict settings
cargo clippy -- -D warnings

# 4. Format check
cargo fmt --check
```

### AI-Generated Code Audit Checklist

When reviewing AI-generated Rust code, check for these common issues:

#### üî¥ CRITICAL (Must Fix)

| Issue | What to Look For | Fix |
|-------|------------------|-----|
| **Panics in library code** | `unwrap()`, `expect()`, `panic!()`, `assert!()` | Return `Result` or use `unwrap_or()` |
| **Blocking in async/parallel** | `send()` on bounded channel in rayon | Use `send_timeout()` or `try_send()` |
| **Division by zero** | `x / y` where y could be 0 | Check `y > 0` or use `checked_div()` |
| **Integer overflow** | `a + b`, `a * b` in index math | Use `saturating_add()`, `checked_mul()` |
| **Unsafe float casts** | `f64 as i64` without bounds check | Check `is_finite()` and range first |
| **Empty collection access** | `vec[0]`, `slice.last().unwrap()` | Check `!is_empty()` or use `.get()` |

#### üü° HIGH (Should Fix)

| Issue | What to Look For | Fix |
|-------|------------------|-----|
| **Swallowed errors** | `let _ = result`, `if let Ok(x) = ...` | Log errors, propagate with `?` |
| **Missing error context** | `PathBuf::new()` in errors | Include actual file path |
| **Thread panics ignored** | `handle.join().is_err()` | Extract and log panic message |
| **TOCTOU races** | Check-then-act on files | Use atomic operations or locks |
| **Unbounded collections** | `Vec::new()` in loops | Pre-allocate with `with_capacity()` |

#### üü¢ MEDIUM (Consider Fixing)

| Issue | What to Look For | Fix |
|-------|------------------|-----|
| **Missing traits** | Structs without `Clone`, `PartialEq` | Add derives for usability |
| **Magic numbers** | Hardcoded `32767`, `1024`, etc. | Extract to named constants |
| **Unnecessary clones** | `.clone()` in hot paths | Use references where possible |
| **String vs &str** | `fn foo(s: String)` parameters | Use `&str` if not taking ownership |

### Rust-Specific Patterns to Enforce

```rust
// ‚ùå BAD: Panic on corrupted data
assert!(index < len, "bounds check");

// ‚úÖ GOOD: Return error on corrupted data
if index >= len {
    return Err(Error::InvalidIndex { index, len });
}

// ‚ùå BAD: Blocking send in parallel context
tx.send(job)?; // Can deadlock if receiver crashes

// ‚úÖ GOOD: Timeout-based send
match tx.send_timeout(job, Duration::from_secs(30)) {
    Ok(()) => {}
    Err(SendTimeoutError::Timeout(_)) => warn!("Queue blocked"),
    Err(SendTimeoutError::Disconnected(_)) => break,
}

// ‚ùå BAD: Float to int without validation
let size = float_value as i64; // UB if NaN/Inf

// ‚úÖ GOOD: Validated cast
let size = if float_value.is_finite() && float_value >= 0.0 {
    float_value.min(i64::MAX as f64) as i64
} else {
    0
};

// ‚ùå BAD: Ignoring thread panic
if handle.join().is_err() {
    warn!("Thread panicked");
}

// ‚úÖ GOOD: Extract panic info
match handle.join() {
    Ok(()) => {}
    Err(panic_info) => {
        let msg = panic_info.downcast_ref::<&str>()
            .map(|s| s.to_string())
            .unwrap_or("unknown".to_string());
        error!("Thread panicked: {}", msg);
    }
}
```

### Post-Generation Audit Command

After generating significant code, request:
```
Run a code quality audit focusing on:
1. All unwrap/expect/panic calls
2. All arithmetic that could overflow
3. All float-to-int casts
4. All channel send/recv patterns
5. All file I/O error handling
6. Missing trait derives on public types
```

### Constants Naming Convention

Extract magic numbers to constants with clear names:
```rust
// Audio processing
const SAMPLE_RATE_ANALYSIS: u32 = 22050;
const SAMPLE_RATE_STEMS: u32 = 44100;

// FFT parameters
const NFFT: usize = 4096;
const HOP_LENGTH: usize = 1024;

// PCM conversion
const PCM_I16_MAX: f32 = 32767.0;
const PCM_I16_MIN: f32 = -32768.0;

// Validation bounds
const BPM_MIN_VALUE: f64 = 1.0;
const BPM_MAX_VALUE: f64 = 999.99;
```
